%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                      Homework 7                            %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letter]{article}

\usepackage{lipsum}
\usepackage[pdftex]{graphicx}
\usepackage[margin=1.5in]{geometry}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{framed} 
\usepackage{amsmath}
\usepackage{titling}
\usepackage{fancyhdr}

\pagestyle{fancy}


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\newenvironment{menumerate}{%
  \edef\backupindent{\the\parindent}%
  \enumerate%
  \setlength{\parindent}{\backupindent}%
}{\endenumerate}







%%%%%%%%%%%%%%%
%% DOC INFO %%%
%%%%%%%%%%%%%%%
\newcommand{\bHWN}{7}
\newcommand{\bCLASS}{MATH H104}

\title{\bCLASS: Homework \bHWN}
\author{William Guss\\26793499\\wguss@berkeley.edu}

\fancyhead[L]{\bCLASS}
\fancyhead[CO]{Homework \bHWN}
\fancyhead[CE]{GUSS}
\fancyhead[R]{\thepage}
\fancyfoot[LR]{}
\fancyfoot[C]{}
\usepackage{csquotes}

%%%%%%%%%%%%%%

\begin{document}
\maketitle
\thispagestyle{empty}


%%%%%%% Be sure to set the counter and use menumerate
\setcounter{section}{2}
\section{Functions of a Real Variable}

\begin{menumerate}
	\item 
	\begin{theorem}
		If $f: \mathbb{R} \to \mathbb{R}$ and $|f(t) - f(x)| \leq |t -x|^2 \forall t,x,$ then $f'(x) = 0 \forall x.$
	\end{theorem}

	\begin{proof}
		For all $t,x$ we have the above relation. In particular when $x \neq t$ we also have that $$\frac{|f(t) - f(x)|}{|t -x|^2} \leq |t -x|^2.$$ So we have essentially that $\left|\frac{\Delta f}{\Delta x}\right| \leq |\Delta x|$. Using the limit definition of the derivative we have that $f'(x) \leq \lim_{\Delta x \to 0} |\Delta x| = 0$ for every $x$. Hence, $\forall x$, $f'(x) = 0.$ This completes the proof.
	\end{proof}


	\setcounter{enumi}{3}
	\item 
	\begin{theorem}
		The following is true, $f(n) = \sqrt{n+1} - \sqrt{n} \to 0.$
	\end{theorem}
	\begin{proof}
	Consider that the above expression is equivalent in the following fassion to,
	$$f(n) = \sqrt{n+1} - \sqrt{n}  = \frac{n+1 -n}{\sqrt{n+1} + \sqrt{n}}.$$
	So it follows that $f(n) = \frac{1}{\sqrt{n+1} + \sqrt{n}}.$ It is clear that the above expression tends directly to $0.$ This completes the proof.
	\end{proof}

	\item 
	\begin{theorem}
	Let $f: \mathbb{R} \to \mathbb{R}$ be a continuous function. Furthermore, for all $x \neq 0$ have $f'(x)$ exist. If $\lim_{x\to 0} f'(x) = L,$ $f'(0)$ exists and is equal to $L.$
	\end{theorem}
	\begin{proof}
	Simple. By definition, $f'(0) = \lim_{\Delta x \to 0} \frac{\Delta f}{\Delta x} = \lim_{t\to 0} \frac{f(0)-f(t)}{t}$ which by L'hopital's rule gives that $f'(0) = \lim_{t\to 0}{f'(t)} = :$ which completes the proof.
	\end{proof}


	\setcounter{enumi}{10}
	\item 
	\begin{menumerate}
	 \item
	 \begin{theorem}
		Let $f$ be a real valued function with doamin $(a,b)$. Given that $f''(x)$ exists, then
		$$\lim_{h\to 0} \frac{f(x-h) - 2f(x) + f(x+h)}{h^2} = f''(x).$$
	\end{theorem}
	\begin{proof}
	Since $f''(x)$ exists it must follow that $f'(x)$ and $f(x)$ must exist. Furthermore, these functions are both continuous. Consider the following derivation. 

	Recall that $$f''(x) = \lim_{h\to0}\frac{f'(x+\frac{h}{2}) - f'(x-\frac{h}{2})}{h}$$. Since $f'(z)$ is also itself a limit, we yield the following definition for $f''(x).$
	$$f''(x) = \lim_{h\to0}\lim_{g\to 0} \frac{f'(x+\frac{h+g}{2}) - f'(x + \frac{h - g}{2}) - f'(x -\frac{h-g}{2}) + f'(x-\frac{-h-g}{2})}{gh}.$$
	Since the there is no dependence of $g$ on $h$ and their combination is at most linear, we may redenote the limit as a single limit of $h$ by the change of variables $h=g.$ Upon reordering, this gives exactly definition,
	$$ f''(x)=\lim_{h\to 0} \frac{f(x-h) - 2f(x) + f(x+h)}{h^2}. $$
	\end{proof}
	 \item An example of a function where the limit exists is $f:\mathbb{R} \to \mathbb{R}$ such that $x \mapsto x|x|.$ In this case, taking the limit yields
	  $$ \lim_{h\to 0} \frac{(0-h)|0-h| - 2(0) + (0+h)|0+h|}{h^2}$$
	  or equivalently
	  $$ \lim_{h \to 0} \frac{-h|h| + h|h|}{h^2} = \frac{0}{h^2} = 0$$
	  by L'hopitals theorem. However $f'(x) = 1/2|x|$ whose derivative clearly does not exist at $x= 0$, and thus the theorem does not hold if we are not known to $f''(x)$ existing.


	The better question now is, what is the geometric interpretation of this limit? Clearly in some capacity, $x=0$, is an inflection point of the function. Concavity directly changes at this point, and yet the second derivative does not exist. Taking such a limit and yielding a result may be akin to calculating something called the subgradient of a function. In fact, this approach may yield the most natural subgradient (for the SG method states that any value in $[-1,1]$ may be taken as the subgradient at this point, but $0$ reflects the most information about the given function, does it not?)
	\end{menumerate}

	


	\setcounter{enumi}{14}
	\item \emph{Is the following argument 'bogus'? "If $f$ is a real valued function such that $f(x) = x^2$ when $x < 0$ and $f(x) = x + x^2$ when $x\geq 0$, we have that $f''(x) = 2$ for \textbf{every} $x$."}

	The argument is completeley bogus. The claim may very well be true for $x \in (0,\infty) \cup (-\infty, 0)$ but consider the derivative of the left and right sides of this function. On the left hand we have $2x \to 0$ as $x \to 0$, and on the left, we have $1 + 2x \to 1$ as $x \to 0$. This means that the limits do not agree at 0 from the left and right. Hence the second derivative could not possibly exist at this point. BOGUS!  

	\item
	\begin{menumerate}
	 \item
	 	Before we prove the statement, consider the following lemma.
	 	\begin{lemma}
	 	 If $f: \mathbb{R} \to \mathbb{R}$ such that $x \mapsto x^k$, then the derivative of $f$ at all $x$ is $kx^{k-1}.$ 
	 	\end{lemma}
	 	\begin{proof}
	 	To show the theorem we must equivalently show that for all $x$, $\lim_{\Delta x \to 0} \frac{\Delta f}{\Delta x} = kx^{k-1}.$ This is simply done by expansion of the binomial coefficients of $(x +h)^k$ as follows,
	 	\begin{equation*}
	 	\begin{aligned}
	 	    f'(x) &= \lim_{h\to 0}\frac{(x+h)^k - x^k}{h} \\
	 	    &=  \lim_{h\to 0}\frac{\sum_{m=0}^k \binom km x^mh^{k-m}  - x^k}{h} \\
	 	    &=  \lim_{h\to 0} \binom k{k-1}{\sum_{m=0}^{k-1} \binom {k-1}m x^mh^{k-m}} \\
	 	    &=  \lim_{h\to 0} \binom k{k-1}(x+h)^{k-1} \\
	 	    &= kx^{k-1},
	 	\end{aligned}
	 	\end{equation*}
	 	which is clearly the claim. Hence the proof is complete.
	 	\end{proof}

	 	Now we pose the following theorem. 
	 	\begin{theorem}
	 		If $\ln(x) = \int_1^x \frac{1}{t} dt$, for $x>0$ then $\ln$ is a smooth function.
	 	\end{theorem}
	 	\begin{proof}
	 	To show that $ln$ is a smooth function, we need only show that it has infinite derivatives defined for all values of $x >0.$ This implicitly states that all derivatives, including $\ln$ itself, are continuous, because if the next derivative exists for all $x > 0$ then the derivative or function itself must be continuous.

	 	We claim that for all $n$ and for all $x > 0$ $\ln^{(n)}(x)$ exists and $$\ln^{(n)}(x) = \frac{(n-1)!(-1)^{n-1}}{x^n}.$$ Consider the base case. By the fundamental theorem of calculus $\ln^{(1)}(x) = \frac{1}{x},$ which clearly exists for all $x > 0$ and satisfies the definition posed for $\ln^{(1)}(x)$ Now suppose that $\ln^{(k)}(x)$ exists for all $x>0$, then we wish to show that $\ln^{(k+1)}(x)$ satisfies the above the form. In the following differentiation of $\ln^{(k)}(x)$ we use the quotient rule and Lemma 1.

	 	\begin{equation*}
	 	\begin{aligned}
	 	\ln^{(n)}'(x) &= (k-1)!(-1)^{k-1}\left(\left(x^k\right)^{-1}\right)' \\
	 	&= (k-1)!(-1)^{k-1}\frac{0-(x^k)'}{(x^k)^2} \\
	 	&= (k-1)!(-1)^{k-1}\frac{-kx^{k-1}}{(x^k)^2} \\
	 	&= (k-1)!(-1)^{k-1}\left(-kx^{k-1}x^{-2k}\right) \\
	 	&= ((k+1)-1)!(-1)^{(k+1)-1}\left(x^{-{(k+1)}}\right).
	 	\end{aligned}
	 	\end{equation*}
	 	This illustrates that $\ln^{(k)}(x)$ of the form aforementioned implies $\ln^{(k+1)}(x)$ is also of the same form. 

	 	By induction all derivatives must be of the form. Furthermore the form exists in the reals for $x>0$ and by the logic from the beginning of the proof, we have that all derivatives are therefore continuous. Hence $\ln$ is a smooth function!
	 	\end{proof}
	 \item 
	 \begin{theorem}
	  For every $x,y > 0$, $\ln(xy) = \ln(x) +\ln(y).$
	 \end{theorem}
	 \begin{proof}
	   Fix $y$ and let $f(x) = \ln(xy) - \ln(x) - \ln(y).$ Equivalently we have that 
	   \begin{equation*}
	   \begin{aligned}
	       f(x) &= \int_1^{xy} 1/t\ dt -\int_1^{y} 1/t\ dt - \int_1^{y} 1/t \ dt \\
	       &= \int_x^{xy} 1/t\ dt - \int_1^{y} 1/t\ dt 
	   \end{aligned}
	   \end{equation*}
	   Performing the change of variables, $u = t/x$ yields that, 
	   $$f(x) = \int_1^{y} 1/u\  du - \int_1^{y} 1/t\ dt \equiv 0$$
	   for all $x.$ Thus $\ln(xy) - \ln(x) -\ln(y) = 0$ for all $x,y$ since $y$ was fixed. This completes the proof.
	 \end{proof}
	 \item 
	 \begin{theorem}
	     The function $\ln$ is monotone increasing and $\ln$ is surjective.
	 \end{theorem}
	 \begin{proof}
	 	We show that $\ln$ is monotone increasing. By the fundamental theorem of calculus, we have that $\ln(x)$ has derivative $1/x$ which is positive for all $x> 0$ if and only if the $\ln(x)$ is monotone increasing by definition.

	 	Now we wish to show that the range of $\ln$ is all of $\mathbb{R}.$ We knlow that $\ln \pi  = \int_1^\pi 1/t\ dt > 0$ and by $\ln (xy) = \ln x + \ln y, \ln \pi^2 = 2\ln \pi.$ In fact for all $n$ $\ln \pi^n = n \ln \pi.$ By the intermediate value theorem, every value between $\ln \pi ^n $ and $\ln \pi^{n+1}$ is achieved as $\ln$ is smooth. Furthermore, since $n\to \infty$ implies $n\ln \pi \to \infty$ we can expand the intermediate value theorem to all positive $n$ and yield that $\ln$ achives all values between $\ln \pi$ and $\infty.$ The same process can be applied for negative $n$. Thus $\ln$ achieves all values of $\mathbb{R}.$
	 \end{proof}
	\end{menumerate}


	\setcounter{enumi}{19}
	\item
	\begin{theorem}
	Show that $\mathbb{Q}^c$ cannot be the coutnable untion of closed intervals in $\mathbb{R}.$
	\end{theorem}
	\begin{proof}
	Since $cl(\mathbb{Q}^c) = \mathbb{R} = cl(\mathbb{Q})$, it is dense in $\mathbb{R}.$ Furthermore we have that the $cl(\mathbb{Q}) = int(\mathbb{Q}^c)^c$ and that $int(\mathbb{Q})^c = cl(\mathbb{Q}^c)$. Finally $\mathbb{R} = int(\mathbb{Q}^c)^c \implies \mathbb{R}^c = int(\mathbb{Q}^c) = \emptyset.$ So the interior of $\mathbb{Q}^c$ is empty.

	Now suppose that $\mathbb{Q}^c$ is the countable union of closed sets in $\mathbb{R}.$ Baire's Theorem states that at least one of these sets must have a non-empty interior, which implies that $\mathbb{Q}^c$ has a non-empty interior. This contradicts the fact that $\mathbb{Q}^c$ has a empty interior, and hence $\mathbb{Q}^c$ cannot be the countable union of closed intervals in $\mathbb{R}.$
	\end{proof}

\end{menumerate}



\end{document}